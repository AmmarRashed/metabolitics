
 Pipeline(steps=[('vect2', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,
        sparse=False)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=0.001, class_weight=None, du...ty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]) 

train accuracy: 1.000000
test accuracy: 0.909091

              precision    recall  f1-score   support

         bc       0.90      0.96      0.93        28
          h       0.93      0.81      0.87        16

avg / total       0.91      0.91      0.91        44

train accuracy: 1.000000
test accuracy: 0.930233

              precision    recall  f1-score   support

         bc       0.93      0.96      0.95        28
          h       0.93      0.87      0.90        15

avg / total       0.93      0.93      0.93        43

train accuracy: 1.000000
test accuracy: 0.837209

              precision    recall  f1-score   support

         bc       0.82      0.96      0.89        28
          h       0.90      0.60      0.72        15

avg / total       0.85      0.84      0.83        43

train accuracy: 1.000000
test accuracy: 0.976190

              precision    recall  f1-score   support

         bc       1.00      0.96      0.98        27
          h       0.94      1.00      0.97        15

avg / total       0.98      0.98      0.98        42

train accuracy: 1.000000
test accuracy: 0.976190

              precision    recall  f1-score   support

         bc       0.96      1.00      0.98        27
          h       1.00      0.93      0.97        15

avg / total       0.98      0.98      0.98        42


 Pipeline(steps=[('vect2', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,
        sparse=False)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=0.001, class_weight=None, du...ty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]) 

kfold test accuracy: [ 0.90909091  0.93023256  0.8372093   0.97619048  0.97619048]
mean: 0.925782744387
std: 0.0514306361962
kfold test f1_micro: [ 0.90909091  0.93023256  0.8372093   0.97619048  0.97619048]
mean: 0.925782744387
std: 0.0514306361962

 Pipeline(steps=[('vect2', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,
        sparse=False)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=0.001, class_weight=None, du...ty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]) 

train accuracy: 1.000000
test accuracy: 0.909091

              precision    recall  f1-score   support

         bc       0.90      0.96      0.93        28
          h       0.93      0.81      0.87        16

avg / total       0.91      0.91      0.91        44

train accuracy: 1.000000
test accuracy: 0.930233

              precision    recall  f1-score   support

         bc       0.93      0.96      0.95        28
          h       0.93      0.87      0.90        15

avg / total       0.93      0.93      0.93        43

train accuracy: 1.000000
test accuracy: 0.837209

              precision    recall  f1-score   support

         bc       0.82      0.96      0.89        28
          h       0.90      0.60      0.72        15

avg / total       0.85      0.84      0.83        43

train accuracy: 1.000000
test accuracy: 0.976190

              precision    recall  f1-score   support

         bc       1.00      0.96      0.98        27
          h       0.94      1.00      0.97        15

avg / total       0.98      0.98      0.98        42

train accuracy: 1.000000
test accuracy: 0.976190

              precision    recall  f1-score   support

         bc       0.96      1.00      0.98        27
          h       1.00      0.93      0.97        15

avg / total       0.98      0.98      0.98        42


 Pipeline(steps=[('vect2', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,
        sparse=False)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,
  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=0.001, class_weight=None, du...ty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]) 

kfold test accuracy: [ 0.90909091  0.93023256  0.8372093   0.97619048  0.97619048]
mean: 0.925782744387
std: 0.0514306361962
kfold test f1_micro: [ 0.90909091  0.93023256  0.8372093   0.97619048  0.97619048]
mean: 0.925782744387
std: 0.0514306361962
